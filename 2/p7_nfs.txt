문제 내용:
서울지사에서 서버관리자로 일하고 있는 도중 본사에서 급한 연락을 받았다
본사 서버에서 용량이 부족한데 본사 서버관리자가 휴가 및 외근으로 인해 작업을 할 수 있는 사람이 없다고 할때
서울지사에서 본사에 5GB 용량을 확보해주기
(단, 지사 머신에 HDD 추가 후 진행)

*용량 제공은 재부팅 후에도 자동으로 동작되도록 설정
*스냡샷 되돌린 후에는 putty를하나만 켜고 한다
(putty를 nfs server에 연결, nfs client는 nfs server에서 원격 제어)


문제 해결 :

서버측에서는 일단 5GB 라는 용량을 정해서 본사에게 제공해줘야하기 때문에, 이 부분적인 제공을 위한 파티션을 일단 나눠줘야합니다.
어떠한 디스크인지는 별로 상관 없으나, 당연하게도 5GB 이상의 용량 및 공간이 필요합니다.

이번 상황에서는 sdb 디스크를 설정하여 본사에게 제공하겠습니다.

fdisk /dev/sdb
를 입력해서, sdb 디스크에 관한 파티션 설정을 시작합니다.

n
을 입력해서 새로운 파티션을 생성합니다.

p
를 입력하거나, 아무것도 입력하지 않은것으로써 프라이머리 파티션을 제공합니다. 프라이머리 파티션이 전부 차있다면, e(xtended)파티션을 제공해줘야합니다.
이유야 어쨌든, 5GB짜리 통으로 된 파티션을 제공해야합니다.

1
을 입력하거나, 아무것도 입력하지 않은것으로써 '파티션의 고유번호'를 붙혀줍니다.


First sector (2048-10485759, default 2048) :
같은 구문이 나온다면

아무것도 입력하지 않음
으로써 기본값으로 넘깁니다. 이는 파티션 내부의 정렬에 관한 내용입니다만, 웬만하면 기본값으로 하는게 좋습니다. (http://rette.iruis.net/2018/01/fdisk%EB%A1%9C-4096-%EC%84%B9%ED%84%B0-%EC%A0%95%EB%A0%AC%EB%90%9C-%ED%8C%8C%ED%8B%B0%EC%85%98-%EC%83%9D%EC%84%B1/ , https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=merry_3&logNo=221540218022 발췌)

Last sector, +sectors of +size{K,M,G} (2048-10485759, default 10485759):
같은 구문이 나온다면

5G
를 입력해주거나, 애초에 디스크 용량이 5G짜리 디스크라면 그냥 엔터를 눌러서 넘기면 됩니다.

Command (m for help) : 
라는 구문이 나온다면,

w
를 입력해서 fdisk 를 종료합니다.


.


이제 본사에 제공할 5GB 용량의 파티션을 생성하는 과정을 마쳤습니다.

그럼에도 잘 설정이 됐는지 확인하기 위해서

mkfs.xfs /dev/sdb1
를 입력합니다. 아까 설정한 파티션 이름(sdb) 뒤에 '파티션의 고유번호'(1)를 붙힌다음, mkfs.xfs 뒤에 붙혀줍니다.
위의 구문은 mkfs 명령어를 통해 /def 디렉터리 안에 있는 sdb1 파티션을 xfs 형식으로써 포맷하는것을 뜻합니다.

meta-data=/dev/sdb1              isize=512    agcount=4, agsize=327616 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0, sparse=0
data     =                       bsize=4096   blocks=1310464, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal log           bsize=4096   blocks=2560, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0

를 동반한 여러가지 정보가 출력된다면 정상적인 과정을 거친것입니다.


.


vi /etc/fstab
을 입력하여, 위에 설정해준 sdb1 파티션이 재부팅 된 후에도 자동으로 마운트(오토마운트)되도록 설정해주기 시작하겠습니다.

파일의 말단에
/dev/sdb1       /nfs        xfs     defaults    0 0
을 입력하여 아래와 같은 의미의 설정을 합니다.
(
/dev/sda1       /nfs     xfs     defaults        0 0
장치명          : /dev/sda1
마운트 포인트   : /nfs
장치의 fs type  : xfs
마운트 옵션     : default
dump 운용       : 0
부팅시 fsck 동작: 0
)


.


이때, 이 파티션을 마운트 할 부분을 /nfs라고 설정해줬는데, 당연하게도 이 파일이 없으면 마운트가 안되고, 제공이 안될테니
ls /nfs
를 입력해서 /nfs 가 없다면
mkdir /nfs
를 입력해서 /nfs를 만들어줍니다.


.


이제 서버측에서 nfs 서비스를 설정해줄겁니다.

systemctl restart nfs
라고 입력하여 nfs를 (재)시작합니다.

systemctl status nfs
를 입력해서 중간에 'Active: active'라고 (초록색 글자로)출력되어있다면 문제없이 작동하는것입니다. 일단 이 이후의 작업을 하려면 이 확인절차는 반드시 필요합니다.

nfs가 정상적으로 작동하는것을 확인했으니, 방화벽을 설정하여 이 nfs서비스에 관한 포트는 예외로 둡니다.

firewall-cmd --permanent --add-service=nfs
를 입력하여 firewall(방화벽)을 통해 nfs서비스 통신을 할 수 있도록 방화벽 설정을 해줍니다.

firewall-cmd --reload
를 입력하여 firewall(방화벽)설정을 해준것을 reload(재시작)함으로써 다시 시작합니다.


.


이제 서버에서 해야하는 모든 과정을 마쳤습니다.
클라이언트로 넘어가는 과정을 거치고, 서버에 접속하겠습니다.
지금의 상황에서는 본사에 아무도 없기 때문에 ssh로 접속하여 실질적으로는...
'server 에서 client로 ssh 접속을 해서 client가 server에 접속하는것'이 될 예정입니다.


.


ssh 192.168.10.129
를 입력하여 클라이언트에 ssh 접속을 합니다.

Are you sure you want to continue connecting (yes/no)?
라는 구문이 나오면

yes
를 입력합니다. 위의 구문은 ssh 통신의 위한 공개키를 생성하는것에 관한 허락을 구하는 내용입니다. (https://info-lab.tistory.com/254 발췌)


ssh 의 통신 과정으로써 당연한 이야기겠지만, 서버에서 root로써 작업하고 있었다면 ssh [클라이언트 아이피 주소] 를 통해 클라이언트에 ssh 접속을 할 때에도 root로써 들어가게 됩니다. 우리가 접속할 클라이언트의 root라는 유저 또한 (최상위 권한을 가진)관리자 라는 가정 하에 상황을 진행합니다.

root@192.168.10.129's password:
라는 구문이 나온다면 클라이언트의 root계정의 비밀번호를 입력하면 됩니다.


.


이제 서버에서 제공해준 파티션을 받아서 사용해야합니다.
서버에서 받은 파티션을 가지고 있으면서, 클라이언트가 재부팅 되었을 때도 사용할 예정인 상황이니, autofs 패키지를 다운받겠습니다.(그저 auto mount 기술이 필요한 경우 위와 같이 해도 되지만 이번에는 경험을 위하여 이와같이 진행했습니다.)

yum -y install autofs-*
를 입력하여 autofs 에 관련된 패키지는 모두 받습니다.
다운로드가 끝난 후, 'Complete!'라는 구문이 나오면 말 그대로 정상적으로 설치가 됐음을 뜻합니다.

vi /etc/autofs.conf
라는 명령어를 입력하여 autofs 에 대한 설정을 건드립니다.

해당 파일에
browse_mode = 
가 있는 곳에

browse_mode = yes
로 바꿔줍니다. 바꿔준 해당 줄(라인)에는 이 구문 이외에는 아무것도 적지 않도록 합니다.

:wq
를 입력하여 저장하고, vi를 빠져나옵니다.

이제 실질적으로 마운트에 대한 정보를 다뤄야 하니,

vi /etc/auto.misc
를 입력하여 문서를 엽니다.

문서의 말단에
nfs_auto    -rw,hard,intr       192.168.10.128:/nfs
이라고 입력해줍니다.해석은 아래와 같습니다.
nfs_auto    : 마운트 포인트 실질적인 경로는 /misc/nfs_auto 로 됩니다.(디렉토리입니다.)
-rw         : read , write 를 하겠다는 의미입니다. 읽기 전용은 ro(read only) 로 적어야합니다.
,           : 구분자
hard        : soft와 hard가 있습니다. hard라면 연결이 끊긴다면 연결 시도를 더 하지 않고 그저 끊어버립니다. soft라면 연결이 끊길경우 연결을 계속해서 시도합니다.
,           : 구분자
intr        : 비정상 종료가 발생했을 경우, 연결을 유지한다는 내용입니다.
192.168.127.128:/nfs : 장치명입니다. 서버가 공유해주는 디렉토리에 대한 부분입니다.

exit
를 입력해서 서버측에서 실행하는 클라이언트를 향한 ssh 접속을 중단합니다.

vi /etc/exports
를 입력하여, client 에서 접속해서 client 의 로컬 디렉토리처럼 사용할 수 있게 설정해주도록 하겠습니다.
(https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=hanajava&logNo=220422771247 발췌)

해당 문서 말단에

/nfs    192.168.10.129(rw,no_root_squash,sync)
를 입력합니다. 의미는 아래와 같습니다.
/nfs    : 제공자 측에서 제공해줄 파티션이 마운트된 파일 위치
192.168.10.129 : 사용자 측의 아이피
rw      : 작업 형식. 일고, 쓰는것 모두를 허용한다는 내용이다.
no_root_squash : client의 root를 서버의 root로 매핑 (최상위 관리자 접속으로 시도하는 경우, 상대방의 최상위 관리자의 이름이 어떻게 되든지간에 '최상위 관리자'라는 것에 맞춰 연결해줌)
sync    : 파일 시스템이 변경되면 즉시 동기화
(https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=musalyh&logNo=220710277058 발췌)


.


이제 client 에 관한 추가적인 설정을 마쳤습니다.
따라서 nfs를 다시 시작해주고, 상태를 살펴보겠습니다.

systemctl restart nfs
를 입력하여 nfs 서비스를 다시 시작하고,

systemctl status nfs
를 입력하여 nfs 서비스의 상태를 살펴봅니다.
아까와 같이 Active: active 같은 설정이 (초록색 글자로)나와있다면 성공입니다.

systemctl enable nfs
를 입력하여 만약에 서버가 재부팅 되는 상황에서도 nfs 서비스가 자동으로 서비스를 할 수 있게 해줍니다.


다시 클라이언트로 ssh 접속을 통해 마운트가 잘 됐는지, nfs 설정이 올바르게 들어갔는지 확인해보겠습니다.


.


ssh 192.168.10.129
를 입력하여 클라이언트(client : 192.168.10.129)에 접속합니다.

root@192.168.10.129's password:
와 같은 구문이 나온다면, client의 root의 비밀번호(password)를 입력해줍니다.

systemctl restart autofs
를 입력하여 오토 마운트 서비스를 (재)시작합니다.

systemctl status autofs
를 입력하여 autofs 서비스가 정상적으로 돌아가고 있는지 확인해봅니다.
위에서 nfs 서비스의 상태를 살펴볼 때와 같이, Active: active 라는 구문이 (초록색으로) 출력되면 정상적으로 작동되는것을 의미합니다.

ls -al /misc
를 입력하여 nfs_auto 디렉토리가 정상적으로 제자리에 잘 있는지 확인합니다.
왜 /nfs_auto 가 아니라 /misc를 하는 이유는 이 문서 176 즈음의 '/misc/nfs_auto'키워드와 함께 서술되어 있습니다.

systemctl enable autofs
를 입력하여 autofs가 재부팅 될 시에도 자동으로 시작할 수 있게 해줍니다.
(https://www.lesstif.com/system-admin/systemd-system-daemon-systemctl-24445064.html 발췌)

init 6
를 입력하여

최종적인 확인을 위하여 클라이언트를 재시작하겠습니다.


.


이렇게 된다면
Connection to 192.168.10.129 closed by remote host.
Connection to 192.168.10.129 closed.
같은 구문이 나오며 서버측에서 진행한 클라이언트를 향한 ssh 통신이 끊기게 됩니다.

서버측에서도 이때까지 해온 모든 과정을 예외없이 정상적으로 적용시키기 위하여 

init 6
를 입력합니다.


.


서버측에서 진행하는 과정입니다.

df -h
를 입력하여 클라이언트가 접속하고싶은 /nfs가 정상적으로 마운트 되어있는지,
용량은 어떤지 확인합니다.

출력문 중에
/dev/sdb1   5.0G    33M     5.0G    1%  /nfs
같은 구문이 있다면 정상적으로 작동하고있는것을 뜻합니다.

exportfs -v
를 입력하여 exports 파일에서 설정한 nfs 공유 파티션(또는 디렉토리) 가 어떤것이 있는지 확인합니다.

/nfs    192.168.10.129(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)
같은 구문이 나온다면 성공입니다.

이제 재부팅 하는 상황에도 다시 자동으로 서비스 해줄 수 있는 상황에 도달했습니다. 클라이언트 측에서는 어떻게 사용할 수 있는지 확인해보겠습니다.

ssh 192.168.10.129
를 입력하여 클라이언트로 접속합니다.


.

클라이언트의 root 패스워드를 입력하여 ssh 연결을 성립시킵니다.

ls -l /misc
를 입력하여

파일이 정상적으로 위치해있는지 확인합니다.

이제 클라이언트가 서버의 디렉토리에 무언가 정상적으로 적을 수 있는지, 꺼내오고, 읽을 수 있는지 확인하는 절차만이 남았습니다.

cp /etc/inittab /misc/nfs_auto
를 입력하여 nfs_auto에 무언가 적어보겠습니다.

ls -al /misc/nfs_auto
를 입력하여, inittab 이 정상적으로 작성됐는지 확인해봅니다.

-rw-r--r-- 1 root root 511 11월  19 20:23 inittab
같은 구문이 나온다면 성공입니다.
서버측의 디렉토리에 쓴건지 확인하기 위하여 다시 서버로 넘어가겠습니다.


.

exit 를 입력하여 ssh 접속을 종룧바니다.

ls -l /nfs
를 입력하여 nfs 서비스를 통해 nfs에 정상적으로 inittab 이 들어가 있는지 확인합니다.

-rw-r--r-- 1 root root 511 11월  19 20:23 inittab
같은 구문이 출력되는 경우, 정상적으로 작동하는것을 뜻합니다.

